{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [ -2.27366000e-05]\n",
      "[0 1] [ 0.99708068]\n",
      "[1 0] [ 0.99559309]\n",
      "[1 1] [-0.00910336]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD8CAYAAACo9anUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5AxQ/12FHQwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22443233a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "                \n",
    "        graph = plt.plot(error)\n",
    "        \n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
