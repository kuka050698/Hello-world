{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [ 0.01140526]\n",
      "[0 1] [ 0.99315528]\n",
      "[1 0] [ 0.99368411]\n",
      "[1 1] [  6.92727411e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x267e3764550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "array  = []\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            array.append(abs(error))\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "        \n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))\n",
    "    plt.plot(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
